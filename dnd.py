# -*- coding: utf-8 -*-
"""DND.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10BsoBEcrHjL6RDzxjkRW2fiehYnvJO2t
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import cv2
import matplotlib.pyplot as plt
import numpy as np
from google.colab.patches import cv2_imshow
from random import shuffle

def getLabels(typ):
  if typ == 0: #open
    return [1,0]
  else:        #close
    return [0,1]

from skimage.transform import resize  # resizing images


items1 = os.listdir("/content/drive/My Drive/Datasets/open_eye")
items2 = os.listdir("/content/drive/My Drive/Datasets/close_eye")

i = 0

IMG_SIZE = 24
x_data = np.empty((len(items1)+len(items2), IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)
y_data = np.empty((len(items1)+len(items2),2),dtype=np.float32)


for each_image in items1:
  
  full_path = "/content/drive/My Drive/Datasets/open_eye/" + each_image
  image = cv2.imread(full_path)
  #print(image.shape)
  img_cvt = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
  img = resize(img_cvt, output_shape=(IMG_SIZE, IMG_SIZE, 1), preserve_range=True)
  x_data[i] = img
  y_data[i] = [1.0,0.0]

  i += 1
  #print(img_cvt.shape)
  #cv2_imshow(image)
  #print(image)

len(items1)
#len(items2)

print(i)

full_path = "/content/B0.jpg"
img = cv2.imread(full_path)
res = cv2.resize(img, dsize=(24, 24), interpolation=cv2.INTER_CUBIC)
cv2_imshow(res)
res.shape

from google.colab.patches import cv2_imshow
cv2_imshow(x_data[0])

print(len(items1))
print(len(items2))
print(i)

for each_image in items2:
  full_path = "/content/drive/My Drive/Datasets/close_eye/" + each_image
  image = cv2.imread(full_path)
  img_cvt = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
  img = resize(img_cvt, output_shape=(IMG_SIZE, IMG_SIZE, 1), preserve_range=True)
  x_data[i] = img
  y_data[i] = [0.0,1.0]

  i += 1

#x_data.shape

from keras.models import Sequential 
from keras.layers import Dropout,Conv2D,Flatten,Dense, MaxPooling2D, BatchNormalization 
from keras.layers.normalization import BatchNormalization 
from keras.utils import np_utils

x_data = x_data/255
x_data[0].shape

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split( x_data, y_data, test_size=0.25, random_state=4)
print ('Train set:', x_train.shape,  y_train.shape)
print ('Test set:', x_test.shape,  y_test.shape)

model=Sequential()

model.add(Conv2D(32,kernel_size=(3, 3), activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,1)))
model.add(MaxPooling2D(pool_size=(1,1)))

model.add(Conv2D(32,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(1,1)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(1,1)))

model.add(Dropout(0.25))
model.add(Flatten())

model.add(Dense(128,activation='relu'))

model.add(Dropout(0.50))

model.add(Dense(2, activation='softmax'))

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=20,epochs=30,verbose=1)

import time
t = time.time()

export_path_keras = "/content/drive/MyDrive/Datasets/cnnEye.h5".format(int(t))
print(export_path_keras)

model.save(export_path_keras)

print(model.summary())